{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "im\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the prepared MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c939cd63305c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MNIST_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "train_X = mnist.train.images\n",
    "train_y = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "test_X = mnist.test.images \n",
    "test_y = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a CNN model that can classify MNIST images w.r.t. the underlying digits 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, labels, mode):\n",
    "    \n",
    "    # declare an input layer by reshaping the input feature to an arbitrary sequence (batch size) of 28x28 images with 1 channel\n",
    "    input_layer = \n",
    "    \n",
    "    # declare a 2-d convolutional layer with 8 filters, 5x5 kernels, \"same\" padding and ReLU activation function\n",
    "    conv1 = \n",
    "    \n",
    "    # declare a 2-d  max pooling layer with 2x2 pool size and stride 2\n",
    "    pool1 = \n",
    "    \n",
    "    # declare a 2-d convolutional layer with 16 filters, 5x5 kernels, \"same\" padding and ReLU activation function\n",
    "    conv2 = \n",
    "    \n",
    "    # declare a 2-d  max pooling layer with 2x2 pool size and stride 2\n",
    "    pool2 = \n",
    "    \n",
    "    # flatten the last layer to an arbitray number (bathc size) of 1-d units\n",
    "    pool2_flat = \n",
    "    \n",
    "    # declare a dense layer with 64 units and ReLU activation function\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=64, activation=tf.nn.relu)\n",
    "    \n",
    "    # declare a dense layer with 10 units (digit 0-9 output classes/logits)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "\n",
    "    predictions = tf.argmax(input=logits, axis=1)\n",
    "    \n",
    "    # return the estimator when predicting (no loss and training function needs to be defined here)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # declare the loss function sparse softmax cross entropy\n",
    "    loss = \n",
    "\n",
    "    # declare a gradient descent optimizer with learning rate 0.001\n",
    "    optimizer = \n",
    "    \n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "    # define the accuracy error metric\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": \n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, predictions=predictions, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Estimator and train the model for 25000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(model_fn=model, model_dir=\"ex_05_mnist_model\")\n",
    "\n",
    "train_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_X}, y=train_y, batch_size=100, num_epochs=None, shuffle=True)\n",
    "mnist_classifier.train(input_fn=train_input, steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": test_X}, y=test_y, num_epochs=1, shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure, subplots = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        subplots[i][j].axis('off')\n",
    "        subplots[i][j].imshow(np.reshape(test_X[j+10*i], (28,28)), cmap='binary')\n",
    "print(\"true labels:\")\n",
    "print(test_y[:100])\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": test_X[:100]}, shuffle=False)\n",
    "predictions = np.array([label for label in mnist_classifier.predict(input_fn=predict_input_fn)])\n",
    "print(\"predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
